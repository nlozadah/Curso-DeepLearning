{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 06\n",
    "# TensorFlow and Keras\n",
    "\n",
    "### Presentado por\n",
    "\n",
    "# Nocol√°s Lozada cod. 201727313\n",
    "# Camilo Yate cod. 201630371\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "from sklearn.datasets.samples_generator import make_moons\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Functions for plotting 2D data and decision regions\n",
    "\n",
    "def plot_data(X, y):\n",
    "    y_unique = np.unique(y)\n",
    "    colors = pl.cm.rainbow(np.linspace(0.0, 1.0, y_unique.size))\n",
    "    for this_y, color in zip(y_unique, colors):\n",
    "        this_X = X[y == this_y]\n",
    "        pl.scatter(this_X[:, 0], this_X[:, 1],  c=color,\n",
    "                    alpha=0.5, edgecolor='k',\n",
    "                    label=\"Class %s\" % this_y)\n",
    "    pl.legend(loc=\"best\")\n",
    "    pl.title(\"Data\")\n",
    "\n",
    "def plot_decision_region(X, pred_fun):\n",
    "    min_x = np.min(X[:, 0])\n",
    "    max_x = np.max(X[:, 0])\n",
    "    min_y = np.min(X[:, 1])\n",
    "    max_y = np.max(X[:, 1])\n",
    "    min_x = min_x - (max_x - min_x) * 0.05\n",
    "    max_x = max_x + (max_x - min_x) * 0.05\n",
    "    min_y = min_y - (max_y - min_y) * 0.05\n",
    "    max_y = max_y + (max_y - min_y) * 0.05\n",
    "    x_vals = np.linspace(min_x, max_x, 30)\n",
    "    y_vals = np.linspace(min_y, max_y, 30)\n",
    "    XX, YY = np.meshgrid(x_vals, y_vals)\n",
    "    grid_r, grid_c = XX.shape\n",
    "    ZZ = np.zeros((grid_r, grid_c))\n",
    "    for i in range(grid_r):\n",
    "        for j in range(grid_c):\n",
    "            ZZ[i, j] = pred_fun(XX[i, j], YY[i, j])\n",
    "    pl.contourf(XX, YY, ZZ, 30, cmap = pl.cm.coolwarm, vmin= 0, vmax=1)\n",
    "    pl.colorbar()\n",
    "    pl.xlabel(\"x\")\n",
    "    pl.ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Improving the Keras text classifier\n",
    "\n",
    "Your goal is to improve the performance of the text classifier in the Keras handout. This is are the things that you need to try:\n",
    "\n",
    "* Different activation functions for the hidden layer (https://keras.io/activations/)\n",
    "* Different optimizers (https://keras.io/optimizers/)\n",
    "* Add dropout between the hidden layer and the output layer (https://keras.io/layers/core/#dropout)\n",
    "* Different initializers for the dense layers (https://keras.io/initializers/)\n",
    "\n",
    "Try different combinations and report your findings at the end. Which configuration got the best accuracy in test?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "8982 train sequences\n",
      "2246 test sequences\n",
      "46 classes\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from sklearn.datasets.samples_generator import make_moons\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "max_words = 1000\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words,\n",
    "                                                         test_split=0.2)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "print(num_classes, 'classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'dlr', 'and', 'cts', '', '80', 'average', 'companies', 'in', 'income', 'of', 'make', '', '', 'said', '', '', 'a', 'of', 'make', '52', '', 'said', '', 'of', '1987', '', '2', 'of', 'sold', 'general', 'states', 'to', '', 'field', 'securities', 'was', 'agricultural', '', '3', 'it', 'a', '1988', 'said', 'as', 'april', '50', 'term', 'to', 'earlier', '3', 'it', 'but', 'was', 'with', '', 'said', '', 'previously', 'be', 'sell', 'cts', 'previously', 'be', '', 'more', 'earlier', 'of', 'which', 'and', 'said', 'commerce', 'of', '1987', 'was', '', 'august', '3', 'it', 'export', 'april', 'report', 'vice', 'to', 'beef', '3', 'it', '', 'and', '000', 'for']\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "num_words = max(word_index.values()) + 1\n",
    "words = ['']*num_words\n",
    "for word in word_index:\n",
    "    words[word_index[word]] = word\n",
    "print([words[i-2] for i in x_train[101][1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (8982, 1000)\n",
      "x_test shape: (2246, 1000)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (8982, 46)\n",
      "y_test shape: (2246, 46)\n"
     ]
    }
   ],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_1 (Dense)                (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_1 (Activation)      (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_2 (Dense)                (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_2 (Activation)      (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 1s 172us/step - loss: 2.4542 - acc: 0.3630 - val_loss: 2.3069 - val_acc: 0.4260\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 148us/step - loss: 2.1809 - acc: 0.4397 - val_loss: 2.1788 - val_acc: 0.4750\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 145us/step - loss: 2.0693 - acc: 0.4876 - val_loss: 2.0863 - val_acc: 0.4905\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 146us/step - loss: 1.9903 - acc: 0.5032 - val_loss: 2.0180 - val_acc: 0.5061\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 144us/step - loss: 1.9276 - acc: 0.5163 - val_loss: 1.9608 - val_acc: 0.5150\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 0s 58us/step\n",
      "Test score: 1.92646697049\n",
      "Test accuracy: 0.52582368658\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# diferentes tipos de activaci√≥n capa oculta\n",
    "\n",
    "\n",
    "\n",
    "* softmax\n",
    "* relu\n",
    "* tanh\n",
    "* linear\n",
    "* elu\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oftmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_3 (Dense)                (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_3 (Activation)      (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_4 (Dense)                (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_4 (Activation)      (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_softamax = Sequential()\n",
    "model_softamax.add(Dense(256, input_shape=(max_words,)))\n",
    "model_softamax.add(Activation('softmax'))\n",
    "model_softamax.add(Dense(num_classes))\n",
    "model_softamax.add(Activation('softmax'))\n",
    "model_softamax.summary(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_softamax.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 2s 219us/step - loss: 3.6315 - acc: 0.3475 - val_loss: 3.4569 - val_acc: 0.3315\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 2s 192us/step - loss: 3.2789 - acc: 0.3540 - val_loss: 3.1575 - val_acc: 0.3315\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 2s 195us/step - loss: 3.0113 - acc: 0.3540 - val_loss: 2.9468 - val_acc: 0.3315\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 2s 197us/step - loss: 2.8327 - acc: 0.3540 - val_loss: 2.8144 - val_acc: 0.3315\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 2s 196us/step - loss: 2.7230 - acc: 0.3540 - val_loss: 2.7342 - val_acc: 0.3315\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model_softamax.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 0s 95us/step\n",
      "Test score: 2.6777455794\n",
      "Test accuracy: 0.361976847782\n"
     ]
    }
   ],
   "source": [
    "score_softmax = model_softamax.evaluate(x_test, y_test)\n",
    "print('Test score:', score_softmax[0])\n",
    "print('Test accuracy:', score_softmax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "Layer (type)                   Output Shape                Param #    \n",
      "======================================================================\n",
      "dense_5 (Dense)                (None, 256)                 256256     \n",
      "______________________________________________________________________\n",
      "activation_5 (Activation)      (None, 256)                 0          \n",
      "______________________________________________________________________\n",
      "dense_6 (Dense)                (None, 46)                  11822      \n",
      "______________________________________________________________________\n",
      "activation_6 (Activation)      (None, 46)                  0          \n",
      "======================================================================\n",
      "Total params: 268,078\n",
      "Trainable params: 268,078\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_relu = Sequential()\n",
    "model_relu.add(Dense(256, input_shape=(max_words,)))\n",
    "model_relu.add(Activation('relu'))\n",
    "model_relu.add(Dense(num_classes))\n",
    "model_relu.add(Activation('softmax'))\n",
    "model_relu.summary(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_relu.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 1s 176us/step - loss: 2.4796 - acc: 0.4595 - val_loss: 1.9839 - val_acc: 0.5139\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 148us/step - loss: 1.7881 - acc: 0.5581 - val_loss: 1.7584 - val_acc: 0.5895\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 146us/step - loss: 1.6135 - acc: 0.6138 - val_loss: 1.6383 - val_acc: 0.6363\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 146us/step - loss: 1.4953 - acc: 0.6567 - val_loss: 1.5516 - val_acc: 0.6652\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 146us/step - loss: 1.4022 - acc: 0.6830 - val_loss: 1.4841 - val_acc: 0.6830\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model_relu.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 0s 61us/step\n",
      "Test score: 1.46068778191\n",
      "Test accuracy: 0.674977738228\n"
     ]
    }
   ],
   "source": [
    "score_relu = model_relu.evaluate(x_test, y_test)\n",
    "print('Test score:', score_relu[0])\n",
    "print('Test accuracy:', score_relu[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_tanh = Sequential()\n",
    "model_tanh.add(Dense(256, input_shape=(max_words,)))\n",
    "model_tanh.add(Activation('tanh'))\n",
    "model_tanh.add(Dense(num_classes))\n",
    "model_tanh.add(Activation('softmax'))\n",
    "#model_elu.summary(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_tanh.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 1s 184us/step - loss: 2.2105 - acc: 0.4865 - val_loss: 1.8361 - val_acc: 0.5451\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 161us/step - loss: 1.6702 - acc: 0.5945 - val_loss: 1.6420 - val_acc: 0.6207\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 151us/step - loss: 1.5056 - acc: 0.6573 - val_loss: 1.5246 - val_acc: 0.6674\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 165us/step - loss: 1.3938 - acc: 0.6900 - val_loss: 1.4466 - val_acc: 0.6874\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 153us/step - loss: 1.3087 - acc: 0.7120 - val_loss: 1.3864 - val_acc: 0.6986\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model_tanh.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 0s 64us/step\n",
      "Test score: 1.37898335983\n",
      "Test accuracy: 0.690560997355\n"
     ]
    }
   ],
   "source": [
    "score_tanh = model_tanh.evaluate(x_test, y_test)\n",
    "print('Test score:', score_tanh[0])\n",
    "print('Test accuracy:', score_tanh[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_linear = Sequential()\n",
    "model_linear.add(Dense(256, input_shape=(max_words,)))\n",
    "model_linear.add(Activation('linear'))\n",
    "model_linear.add(Dense(num_classes))\n",
    "model_linear.add(Activation('softmax'))\n",
    "#model_elu.summary(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_linear.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 1s 181us/step - loss: 2.1693 - acc: 0.4951 - val_loss: 1.8140 - val_acc: 0.5617\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 155us/step - loss: 1.6270 - acc: 0.6188 - val_loss: 1.6128 - val_acc: 0.6407\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 152us/step - loss: 1.4580 - acc: 0.6686 - val_loss: 1.5002 - val_acc: 0.6674\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 159us/step - loss: 1.3458 - acc: 0.6960 - val_loss: 1.4216 - val_acc: 0.6863\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 164us/step - loss: 1.2620 - acc: 0.7209 - val_loss: 1.3699 - val_acc: 0.7052\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model_linear.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 0s 67us/step\n",
      "Test score: 1.34297478443\n",
      "Test accuracy: 0.707925200383\n"
     ]
    }
   ],
   "source": [
    "score_linear = model_linear.evaluate(x_test, y_test)\n",
    "print('Test score:', score_linear[0])\n",
    "print('Test accuracy:', score_linear[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### elu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_elu = Sequential()\n",
    "model_elu.add(Dense(256, input_shape=(max_words,)))\n",
    "model_elu.add(Activation('elu'))\n",
    "model_elu.add(Dense(num_classes))\n",
    "model_elu.add(Activation('softmax'))\n",
    "#model_elu.summary(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_elu.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 2s 198us/step - loss: 2.2325 - acc: 0.5034 - val_loss: 1.8474 - val_acc: 0.5439\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 1s 163us/step - loss: 1.6604 - acc: 0.6039 - val_loss: 1.6544 - val_acc: 0.6218\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 1s 162us/step - loss: 1.4976 - acc: 0.6563 - val_loss: 1.5438 - val_acc: 0.6674\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 1s 161us/step - loss: 1.3875 - acc: 0.6842 - val_loss: 1.4662 - val_acc: 0.6841\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 1s 163us/step - loss: 1.3029 - acc: 0.7073 - val_loss: 1.4070 - val_acc: 0.6952\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model_elu.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 0s 68us/step\n",
      "Test score: 1.37529943505\n",
      "Test accuracy: 0.694122885156\n"
     ]
    }
   ],
   "source": [
    "score_elu = model_elu.evaluate(x_test, y_test)\n",
    "print('Test score:', score_elu[0])\n",
    "print('Test accuracy:', score_elu[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen\n",
    "\n",
    "A contniuacu√≥n se muestra el accuracy de los distintoss modelos utilizando distintas activaciones para la capa oculta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy elu: 0.694122885156\n",
      "Test accuracy relu: 0.674977738228\n",
      "Test accuracy linear: 0.707925200383\n",
      "Test accuracy tanh: 0.690560997355\n",
      "Test accuracysoftmax : 0.361976847782\n",
      "Test accuracy sigmoid: 0.52582368658\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy elu:', score_elu[1])\n",
    "print('Test accuracy relu:', score_relu[1])\n",
    "print('Test accuracy linear:', score_linear[1])\n",
    "print('Test accuracy tanh:', score_tanh[1])\n",
    "print('Test accuracysoftmax :', score_softmax[1])\n",
    "print('Test accuracy sigmoid:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probar con distintos optimizadores\n",
    "* RMSprop\n",
    "* Adagrad\n",
    "* Adadelta\n",
    "* Adam\n",
    "\n",
    "A partir de aqu√≠ tomamos la activaci√≥n linear en la capa oculta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_2_RMSprop = Sequential()\n",
    "model_2_RMSprop.add(Dense(256, input_shape=(max_words,)))\n",
    "model_2_RMSprop.add(Activation('linear'))\n",
    "model_2_RMSprop.add(Dense(num_classes))\n",
    "model_2_RMSprop.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "model_2_RMSprop.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 2s 282us/step - loss: 1.2143 - acc: 0.7312 - val_loss: 1.0160 - val_acc: 0.7820\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 2s 264us/step - loss: 0.6651 - acc: 0.8492 - val_loss: 0.9190 - val_acc: 0.7864\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 2s 280us/step - loss: 0.4798 - acc: 0.8914 - val_loss: 0.9563 - val_acc: 0.7987\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 3s 357us/step - loss: 0.3780 - acc: 0.9101 - val_loss: 1.0506 - val_acc: 0.7998\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 3s 322us/step - loss: 0.3232 - acc: 0.9240 - val_loss: 1.0710 - val_acc: 0.7853\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model_2_RMSprop.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 0s 82us/step\n",
      "Test score: 1.01439451492\n",
      "Test accuracy: 0.788512911843\n"
     ]
    }
   ],
   "source": [
    "score_2_RMSprop = model_2_RMSprop.evaluate(x_test, y_test)\n",
    "print('Test score:', score_2_RMSprop[0])\n",
    "print('Test accuracy:', score_2_RMSprop[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_2_Adagrad = Sequential()\n",
    "model_2_Adagrad.add(Dense(256, input_shape=(max_words,)))\n",
    "model_2_Adagrad.add(Activation('linear'))\n",
    "model_2_Adagrad.add(Dense(num_classes))\n",
    "model_2_Adagrad.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adagrad\n",
    "model_2_Adagrad.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adagrad(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 2s 304us/step - loss: 1.0993 - acc: 0.7575 - val_loss: 0.9505 - val_acc: 0.7864\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 2s 246us/step - loss: 0.6001 - acc: 0.8666 - val_loss: 0.9134 - val_acc: 0.7964\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 2s 263us/step - loss: 0.4721 - acc: 0.8952 - val_loss: 0.8786 - val_acc: 0.8098\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 2s 192us/step - loss: 0.3994 - acc: 0.9123 - val_loss: 0.8664 - val_acc: 0.8053\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 2s 227us/step - loss: 0.3490 - acc: 0.9230 - val_loss: 0.8879 - val_acc: 0.8131\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model_2_Adagrad.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 0s 94us/step\n",
      "Test score: 0.871606975396\n",
      "Test accuracy: 0.796081923419\n"
     ]
    }
   ],
   "source": [
    "score_2_Adagrad = model_2_Adagrad.evaluate(x_test, y_test)\n",
    "print('Test score:', score_2_Adagrad[0])\n",
    "print('Test accuracy:', score_2_Adagrad[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_2_Adadelta = Sequential()\n",
    "model_2_Adadelta.add(Dense(256, input_shape=(max_words,)))\n",
    "model_2_Adadelta.add(Activation('linear'))\n",
    "model_2_Adadelta.add(Dense(num_classes))\n",
    "model_2_Adadelta.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adadelta\n",
    "model_2_Adadelta.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 3s 385us/step - loss: 1.2710 - acc: 0.7194 - val_loss: 1.0751 - val_acc: 0.7597\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 3s 358us/step - loss: 0.7258 - acc: 0.8331 - val_loss: 0.9826 - val_acc: 0.7842\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 3s 373us/step - loss: 0.5395 - acc: 0.8781 - val_loss: 0.9522 - val_acc: 0.7875\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 3s 330us/step - loss: 0.4355 - acc: 0.9003 - val_loss: 1.0073 - val_acc: 0.7820\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 3s 391us/step - loss: 0.3649 - acc: 0.9130 - val_loss: 0.9485 - val_acc: 0.7898\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model_2_Adadelta.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 0s 80us/step\n",
      "Test score: 0.948198899136\n",
      "Test accuracy: 0.786731967996\n"
     ]
    }
   ],
   "source": [
    "score_2_Adadelta = model_2_Adadelta.evaluate(x_test, y_test)\n",
    "print('Test score:', score_2_Adadelta[0])\n",
    "print('Test accuracy:', score_2_Adadelta[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_2_Adam = Sequential()\n",
    "model_2_Adam.add(Dense(256, input_shape=(max_words,)))\n",
    "model_2_Adam.add(Activation('linear'))\n",
    "model_2_Adam.add(Dense(num_classes))\n",
    "model_2_Adam.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "model_2_Adam.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 4s 529us/step - loss: 1.2453 - acc: 0.7281 - val_loss: 1.0016 - val_acc: 0.7775\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 3s 350us/step - loss: 0.6299 - acc: 0.8578 - val_loss: 0.8984 - val_acc: 0.8031\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 3s 338us/step - loss: 0.4461 - acc: 0.8961 - val_loss: 0.9393 - val_acc: 0.7942\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 3s 335us/step - loss: 0.3484 - acc: 0.9157 - val_loss: 0.9572 - val_acc: 0.8042\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 2s 285us/step - loss: 0.2901 - acc: 0.9287 - val_loss: 1.0062 - val_acc: 0.7942\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model_2_Adam.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 0s 61us/step\n",
      "Test score: 0.974930532044\n",
      "Test accuracy: 0.78272484422\n"
     ]
    }
   ],
   "source": [
    "score_2_Adam = model_2_Adam.evaluate(x_test, y_test)\n",
    "print('Test score:', score_2_Adam[0])\n",
    "print('Test accuracy:', score_2_Adam[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resumen\n",
    "\n",
    "A contninuaci√≥n se muestran los accuracy de los modelo con los distintos tipos de optimizadores utilizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy score_2_RMSprop: 0.788512911843\n",
      "Test accuracy Adagrad: 0.796081923419\n",
      "Test accuracy Adadelta: 0.786731967996\n",
      "Test accuracy Adam: 0.78272484422\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy score_2_RMSprop:', score_2_RMSprop[1])\n",
    "print('Test accuracy Adagrad:', score_2_Adagrad[1])\n",
    "print('Test accuracy Adadelta:', score_2_Adadelta[1])\n",
    "print('Test accuracy Adam:', score_2_Adam[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DROPOUT\n",
    "\n",
    "A contniuaci√≥n se incluye un dropout, con una tasa de 0.5, conservando la activaci√≥n linear en la capa oculta y el optimizador Adagrad que hasta ahora arroja el mejor resultado.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_3_dropout = Sequential()\n",
    "model_3_dropout.add(Dense(256, input_shape=(max_words,)))\n",
    "model_3_dropout.add(Activation('linear'))\n",
    "model_3_dropout.add(Dropout(0.5))\n",
    "model_3_dropout.add(Dense(num_classes))\n",
    "model_3_dropout.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model_3_dropout.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adagrad(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 2s 245us/step - loss: 1.2185 - acc: 0.7328 - val_loss: 1.0295 - val_acc: 0.7775\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 2s 209us/step - loss: 0.7600 - acc: 0.8309 - val_loss: 0.9446 - val_acc: 0.7887\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 2s 204us/step - loss: 0.6310 - acc: 0.8567 - val_loss: 0.9170 - val_acc: 0.8042\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 2s 206us/step - loss: 0.5586 - acc: 0.8734 - val_loss: 0.9026 - val_acc: 0.8020\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 2s 257us/step - loss: 0.4931 - acc: 0.8866 - val_loss: 0.8960 - val_acc: 0.8087\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model_3_dropout.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 0s 63us/step\n",
      "Test score: 0.8683658523\n",
      "Test accuracy: 0.79697239537\n"
     ]
    }
   ],
   "source": [
    "score_3_dropout = model_3_dropout.evaluate(x_test, y_test)\n",
    "print('Test score:', score_3_dropout[0])\n",
    "print('Test accuracy:', score_3_dropout[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inicializador capa denza\n",
    "\n",
    "A continuaci√≥n se muestran distintios inicializadores , con activaci√≥n linear en la capa oculta y optimizador Adagrad\n",
    "\n",
    "* RandomUniform\n",
    "* RandomNormal\n",
    "* TruncatedNormal\n",
    "* VarianceScaling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### score_4_RandomUniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_4_RandomUniform = Sequential()\n",
    "model_4_RandomUniform.add(Dense(256, input_shape=(max_words,),kernel_initializer = 'RandomUniform'))\n",
    "model_4_RandomUniform.add(Activation('linear'))\n",
    "model_4_RandomUniform.add(Dropout(0.5))\n",
    "model_4_RandomUniform.add(Dense(num_classes))\n",
    "model_4_RandomUniform.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model_4_RandomUniform.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adagrad(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 2s 247us/step - loss: 1.1959 - acc: 0.7367 - val_loss: 1.0327 - val_acc: 0.7786\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 2s 230us/step - loss: 0.7416 - acc: 0.8305 - val_loss: 0.9486 - val_acc: 0.7942\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 2s 206us/step - loss: 0.6124 - acc: 0.8617 - val_loss: 0.9149 - val_acc: 0.7976\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 2s 243us/step - loss: 0.5392 - acc: 0.8790 - val_loss: 0.9018 - val_acc: 0.7998\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 2s 275us/step - loss: 0.4844 - acc: 0.8883 - val_loss: 0.8851 - val_acc: 0.8042\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model_4_RandomUniform.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 0s 107us/step\n",
      "Test score: 0.858450887464\n",
      "Test accuracy: 0.798308103321\n"
     ]
    }
   ],
   "source": [
    "score_4_RandomUniform = model_4_RandomUniform.evaluate(x_test, y_test)\n",
    "print('Test score:', score_4_RandomUniform[0])\n",
    "print('Test accuracy:', score_4_RandomUniform[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_4_RandomNormal = Sequential()\n",
    "model_4_RandomNormal.add(Dense(256, input_shape=(max_words,),kernel_initializer = 'RandomNormal'))\n",
    "model_4_RandomNormal.add(Activation('linear'))\n",
    "model_4_RandomNormal.add(Dropout(0.5))\n",
    "model_4_RandomNormal.add(Dense(num_classes))\n",
    "model_4_RandomNormal.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model_4_RandomNormal.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adagrad(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 3s 367us/step - loss: 1.2478 - acc: 0.7251 - val_loss: 1.0512 - val_acc: 0.7742\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 3s 313us/step - loss: 0.7822 - acc: 0.8218 - val_loss: 0.9652 - val_acc: 0.7909\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 3s 321us/step - loss: 0.6553 - acc: 0.8484 - val_loss: 0.9383 - val_acc: 0.7931\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 3s 317us/step - loss: 0.5794 - acc: 0.8666 - val_loss: 0.9142 - val_acc: 0.8009\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 2s 266us/step - loss: 0.5210 - acc: 0.8788 - val_loss: 0.9108 - val_acc: 0.7964\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model_4_RandomNormal.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 0s 89us/step\n",
      "Test score: 0.86388503157\n",
      "Test accuracy: 0.79964381122\n"
     ]
    }
   ],
   "source": [
    "score_4_RandomNormal = model_4_RandomNormal.evaluate(x_test, y_test)\n",
    "print('Test score:', score_4_RandomNormal[0])\n",
    "print('Test accuracy:', score_4_RandomNormal[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TruncatedNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_4_TruncatedNormal = Sequential()\n",
    "model_4_TruncatedNormal.add(Dense(256, input_shape=(max_words,),kernel_initializer = 'TruncatedNormal'))\n",
    "model_4_TruncatedNormal.add(Activation('linear'))\n",
    "model_4_TruncatedNormal.add(Dropout(0.5))\n",
    "model_4_TruncatedNormal.add(Dense(num_classes))\n",
    "model_4_TruncatedNormal.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model_4_TruncatedNormal.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adagrad(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 2s 283us/step - loss: 1.2390 - acc: 0.7286 - val_loss: 1.0385 - val_acc: 0.7731\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 2s 245us/step - loss: 0.7668 - acc: 0.8277 - val_loss: 0.9617 - val_acc: 0.7887\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 2s 220us/step - loss: 0.6494 - acc: 0.8524 - val_loss: 0.9253 - val_acc: 0.7898\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 2s 217us/step - loss: 0.5663 - acc: 0.8731 - val_loss: 0.9082 - val_acc: 0.7942\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 2s 251us/step - loss: 0.5080 - acc: 0.8823 - val_loss: 0.8981 - val_acc: 0.8031\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model_4_TruncatedNormal.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 0s 68us/step\n",
      "Test score: 0.864811734864\n",
      "Test accuracy: 0.793410507569\n"
     ]
    }
   ],
   "source": [
    "score_4_TruncatedNormal = model_4_TruncatedNormal.evaluate(x_test, y_test)\n",
    "print('Test score:', score_4_TruncatedNormal[0])\n",
    "print('Test accuracy:', score_4_TruncatedNormal[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VarianceScaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_4_VarianceScaling = Sequential()\n",
    "model_4_VarianceScaling.add(Dense(256, input_shape=(max_words,),kernel_initializer = 'VarianceScaling'))\n",
    "model_4_VarianceScaling.add(Activation('linear'))\n",
    "model_4_VarianceScaling.add(Dropout(0.5))\n",
    "model_4_VarianceScaling.add(Dense(num_classes))\n",
    "model_4_VarianceScaling.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model_4_VarianceScaling.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adagrad(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/5\n",
      "8083/8083 [==============================] - 2s 253us/step - loss: 1.2047 - acc: 0.7348 - val_loss: 1.0039 - val_acc: 0.7753\n",
      "Epoch 2/5\n",
      "8083/8083 [==============================] - 2s 206us/step - loss: 0.7590 - acc: 0.8316 - val_loss: 0.9515 - val_acc: 0.7909\n",
      "Epoch 3/5\n",
      "8083/8083 [==============================] - 2s 209us/step - loss: 0.6203 - acc: 0.8622 - val_loss: 0.9146 - val_acc: 0.7998\n",
      "Epoch 4/5\n",
      "8083/8083 [==============================] - 2s 211us/step - loss: 0.5447 - acc: 0.8754 - val_loss: 0.8958 - val_acc: 0.8009\n",
      "Epoch 5/5\n",
      "8083/8083 [==============================] - 2s 209us/step - loss: 0.4997 - acc: 0.8849 - val_loss: 0.8862 - val_acc: 0.8031\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "history = model_4_VarianceScaling.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 0s 62us/step\n",
      "Test score: 0.859848294848\n",
      "Test accuracy: 0.796527159394\n"
     ]
    }
   ],
   "source": [
    "score_4_VarianceScaling = model_4_VarianceScaling.evaluate(x_test, y_test)\n",
    "print('Test score:', score_4_VarianceScaling[0])\n",
    "print('Test accuracy:', score_4_VarianceScaling[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumen\n",
    "\n",
    "A continuaci√≥n el accuracy de los modelos con diferentes inicializadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy RandomNormal: 0.79964381122\n",
      "Test accuracy RandomUniform: 0.798308103321\n",
      "Test accuracy TruncatedNormal: 0.793410507569\n",
      "Test accuracy VarianceScaling: 0.796527159394\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy RandomNormal:', score_4_RandomNormal[1])\n",
    "print('Test accuracy RandomUniform:', score_4_RandomUniform[1])\n",
    "print('Test accuracy TruncatedNormal:', score_4_TruncatedNormal[1])\n",
    "print('Test accuracy VarianceScaling:', score_4_VarianceScaling[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones\n",
    "\n",
    "El primer modelo proporcionado arrojaba un accuracy de 0.52 en test. luego de probar distintas formas de activaci√≥n de las neuronas, distintos optimizadores e incializadores, logramos un accuracy de 0.79 con activaci√≥n linear en la capa oculta, optimizador Adagrat, Droopout de 0.5 y intializador dRandomNormal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
